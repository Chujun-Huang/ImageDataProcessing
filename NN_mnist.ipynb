{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time Spent: 9.21s, Train Accuracy: 11.02%\n",
      "Epoch: 1, Time Spent: 9.37s, Test Accuracy: 14.10%\n",
      "Epoch: 2, Time Spent: 15.58s, Train Accuracy: 12.69%\n",
      "Epoch: 2, Time Spent: 15.74s, Test Accuracy: 15.80%\n",
      "Epoch: 3, Time Spent: 21.94s, Train Accuracy: 15.75%\n",
      "Epoch: 3, Time Spent: 22.11s, Test Accuracy: 18.00%\n",
      "Epoch: 4, Time Spent: 28.29s, Train Accuracy: 17.75%\n",
      "Epoch: 4, Time Spent: 28.46s, Test Accuracy: 19.90%\n",
      "Epoch: 5, Time Spent: 34.68s, Train Accuracy: 20.18%\n",
      "Epoch: 5, Time Spent: 34.84s, Test Accuracy: 22.10%\n",
      "Epoch: 6, Time Spent: 41.20s, Train Accuracy: 21.68%\n",
      "Epoch: 6, Time Spent: 41.36s, Test Accuracy: 23.60%\n",
      "Epoch: 7, Time Spent: 47.78s, Train Accuracy: 22.37%\n",
      "Epoch: 7, Time Spent: 47.95s, Test Accuracy: 24.20%\n",
      "Epoch: 8, Time Spent: 54.17s, Train Accuracy: 23.09%\n",
      "Epoch: 8, Time Spent: 54.33s, Test Accuracy: 24.20%\n",
      "Epoch: 9, Time Spent: 61.21s, Train Accuracy: 23.52%\n",
      "Epoch: 9, Time Spent: 61.39s, Test Accuracy: 24.10%\n",
      "Epoch: 10, Time Spent: 67.64s, Train Accuracy: 23.94%\n",
      "Epoch: 10, Time Spent: 67.80s, Test Accuracy: 24.20%\n",
      "Epoch: 11, Time Spent: 80.29s, Train Accuracy: 24.25%\n",
      "Epoch: 11, Time Spent: 80.47s, Test Accuracy: 24.60%\n",
      "Epoch: 12, Time Spent: 91.70s, Train Accuracy: 24.69%\n",
      "Epoch: 12, Time Spent: 92.19s, Test Accuracy: 24.70%\n",
      "Epoch: 13, Time Spent: 103.24s, Train Accuracy: 25.29%\n",
      "Epoch: 13, Time Spent: 103.50s, Test Accuracy: 24.90%\n",
      "Epoch: 14, Time Spent: 119.53s, Train Accuracy: 25.77%\n",
      "Epoch: 14, Time Spent: 119.70s, Test Accuracy: 24.90%\n",
      "Epoch: 15, Time Spent: 125.99s, Train Accuracy: 26.20%\n",
      "Epoch: 15, Time Spent: 126.16s, Test Accuracy: 25.30%\n",
      "Epoch: 16, Time Spent: 138.73s, Train Accuracy: 26.73%\n",
      "Epoch: 16, Time Spent: 139.23s, Test Accuracy: 25.70%\n",
      "Epoch: 17, Time Spent: 153.16s, Train Accuracy: 27.19%\n",
      "Epoch: 17, Time Spent: 153.36s, Test Accuracy: 26.10%\n",
      "Epoch: 18, Time Spent: 163.44s, Train Accuracy: 27.71%\n",
      "Epoch: 18, Time Spent: 163.96s, Test Accuracy: 26.40%\n",
      "Epoch: 19, Time Spent: 172.68s, Train Accuracy: 28.22%\n",
      "Epoch: 19, Time Spent: 172.85s, Test Accuracy: 27.00%\n",
      "Epoch: 20, Time Spent: 181.41s, Train Accuracy: 28.87%\n",
      "Epoch: 20, Time Spent: 181.69s, Test Accuracy: 27.40%\n"
     ]
    }
   ],
   "source": [
    "# 4 layer\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def the function for convert label and image 28x28 into 1 + 728 and save as csv file\n",
    "def convert(imgf, labelf, outf, n):\n",
    "    f = open(imgf, \"rb\")\n",
    "    o = open(outf, \"w\")\n",
    "    l = open(labelf, \"rb\")\n",
    "\n",
    "    f.read(16)\n",
    "    l.read(8)\n",
    "    images = []\n",
    "\n",
    "    for i in range(n):\n",
    "        image = [ord(l.read(1))]\n",
    "        for j in range(28*28):\n",
    "            image.append(ord(f.read(1)))\n",
    "        images.append(image)\n",
    "\n",
    "    for image in images:\n",
    "        o.write(\",\".join(str(pix) for pix in image)+\"\\n\")\n",
    "    f.close()\n",
    "    o.close()\n",
    "    l.close()\n",
    "\n",
    "# convert mnist files in to csv\n",
    "#convert(\"train-images-idx3-ubyte\", \"train-labels-idx1-ubyte\", \"train_10000.csv\", 10000)\n",
    "#convert(\"t10k-images-idx3-ubyte\", \"t10k-labels-idx1-ubyte\", \"test_1000.csv\", 1000)\n",
    "\n",
    "# convert the data from csv to np.array\n",
    "train_file = open(\"train_10000.csv\", 'r')\n",
    "train_list = train_file.readlines()\n",
    "train_file.close()\n",
    "#len(train_list)\n",
    "test_file = open(\"test_1000.csv\", 'r')\n",
    "test_list = test_file.readlines()\n",
    "test_file.close()\n",
    "\n",
    "# NN building\n",
    "class DNN:\n",
    "  def __init__(self, sizes, epochs, lr):\n",
    "    self.sizes = sizes\n",
    "    self.epochs = epochs\n",
    "    self.lr = lr\n",
    "\n",
    "    # number of nodes in each layer\n",
    "    input_layer=self.sizes[0]\n",
    "    hidden_1=self.sizes[1]\n",
    "    hidden_2=self.sizes[2]\n",
    "    output_layer=self.sizes[3]\n",
    "\n",
    "    self.params = {\n",
    "        'W1':np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
    "        'W2':np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
    "        'W3':np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
    "    }\n",
    "  def sigmoid(self, x, derivative=False):\n",
    "      if derivative:\n",
    "          return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "      return 1/(1 + np.exp(-x))\n",
    "\n",
    "  def softmax(self, x, derivative=False):\n",
    "      # Numerically stable with large exponentials\n",
    "      exps = np.exp(x - x.max())\n",
    "      if derivative:\n",
    "          return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "      return exps / np.sum(exps, axis=0)\n",
    "  def forward_pass(self, x_train):\n",
    "      params = self.params\n",
    "\n",
    "      # input layer activations becomes sample\n",
    "      params['A0'] = x_train\n",
    "\n",
    "      # input layer to hidden layer 1\n",
    "      params['Z1'] = np.dot(params[\"W1\"], params['A0'])\n",
    "      params['A1'] = self.sigmoid(params['Z1'])\n",
    "\n",
    "      # hidden layer 1 to hidden layer 2\n",
    "      params['Z2'] = np.dot(params[\"W2\"], params['A1'])\n",
    "      params['A2'] = self.sigmoid(params['Z2'])\n",
    "\n",
    "      # hidden layer 2 to output layer\n",
    "      params['Z3'] = np.dot(params[\"W3\"], params['A2'])\n",
    "      params['A3'] = self.softmax(params['Z3'])\n",
    "\n",
    "      return params['A3']\n",
    "\n",
    "  def backward_pass(self, y_train, output):\n",
    "      params = self.params\n",
    "      change_w = {}\n",
    "\n",
    "      # Calculate W3 update\n",
    "      error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['Z3'], derivative=True)\n",
    "      change_w['W3'] = np.outer(error, params['A2'])\n",
    "\n",
    "      # Calculate W2 update\n",
    "      error = np.dot(params['W3'].T, error) * self.sigmoid(params['Z2'], derivative=True)\n",
    "      change_w['W2'] = np.outer(error, params['A1'])\n",
    "\n",
    "      # Calculate W1 update\n",
    "      error = np.dot(params['W2'].T, error) * self.sigmoid(params['Z1'], derivative=True)\n",
    "      change_w['W1'] = np.outer(error, params['A0'])\n",
    "\n",
    "      return change_w\n",
    "\n",
    "  def update_network_parameters(self, changes_to_w):\n",
    "      for key, value in changes_to_w.items():\n",
    "          self.params[key] -= self.lr * value\n",
    "\n",
    "  def compute_accuracy(self, test_data, output_nodes):\n",
    "      predictions = []\n",
    "      for x in test_data:\n",
    "          all_values = x.split(',')\n",
    "          # scale and shift the inputs\n",
    "          inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "          # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "          targets = np.zeros(output_nodes) + 0.01\n",
    "          # all_values[0] is the target label for this record\n",
    "          targets[int(all_values[0])] = 0.99\n",
    "          output = self.forward_pass(inputs)\n",
    "          pred = np.argmax(output)\n",
    "          predictions.append(pred == np.argmax(targets))\n",
    "\n",
    "      return np.mean(predictions)\n",
    "\n",
    "  def train(self, train_list, test_list, output_nodes):\n",
    "      start_time = time.time()\n",
    "      for iteration in range(self.epochs):\n",
    "          for x in train_list:\n",
    "              all_values = x.split(',')\n",
    "              # scale and shift the inputs\n",
    "              inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "              # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "              targets = np.zeros(output_nodes) + 0.01\n",
    "              # all_values[0] is the target label for this record\n",
    "              targets[int(all_values[0])] = 0.99\n",
    "              output = self.forward_pass(inputs)\n",
    "              changes_to_w = self.backward_pass(targets, output)\n",
    "              self.update_network_parameters(changes_to_w)\n",
    "\n",
    "          accuracy_train = self.compute_accuracy(train_list, output_nodes)\n",
    "          print('Epoch: {0}, Time Spent: {1:.2f}s, Train Accuracy: {2:.2f}%'.format(\n",
    "              iteration+1, time.time() - start_time, accuracy_train * 100))\n",
    "\n",
    "          accuracy_test = self.compute_accuracy(test_list, output_nodes)\n",
    "          print('Epoch: {0}, Time Spent: {1:.2f}s, Test Accuracy: {2:.2f}%'.format(\n",
    "              iteration+1, time.time() - start_time, accuracy_test * 100))\n",
    "\n",
    "\n",
    "# run the NN\n",
    "dnn = DNN(sizes=[784, 128, 64, 10], epochs=20, lr=0.001)\n",
    "dnn.train(train_list, test_list, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time Spent: 12.28s, Train Accuracy: 12.66%\n",
      "Epoch: 1, Time Spent: 12.48s, Test Accuracy: 13.00%\n",
      "Epoch: 2, Time Spent: 28.41s, Train Accuracy: 21.60%\n",
      "Epoch: 2, Time Spent: 28.75s, Test Accuracy: 20.10%\n",
      "Epoch: 3, Time Spent: 50.72s, Train Accuracy: 19.30%\n",
      "Epoch: 3, Time Spent: 51.07s, Test Accuracy: 17.10%\n",
      "Epoch: 4, Time Spent: 76.31s, Train Accuracy: 18.93%\n",
      "Epoch: 4, Time Spent: 76.72s, Test Accuracy: 16.60%\n",
      "Epoch: 5, Time Spent: 101.05s, Train Accuracy: 17.82%\n",
      "Epoch: 5, Time Spent: 101.27s, Test Accuracy: 15.70%\n",
      "Epoch: 6, Time Spent: 123.98s, Train Accuracy: 16.47%\n",
      "Epoch: 6, Time Spent: 124.26s, Test Accuracy: 14.60%\n",
      "Epoch: 7, Time Spent: 147.17s, Train Accuracy: 15.23%\n",
      "Epoch: 7, Time Spent: 147.45s, Test Accuracy: 13.20%\n",
      "Epoch: 8, Time Spent: 167.16s, Train Accuracy: 14.38%\n",
      "Epoch: 8, Time Spent: 167.42s, Test Accuracy: 12.30%\n",
      "Epoch: 9, Time Spent: 191.05s, Train Accuracy: 13.99%\n",
      "Epoch: 9, Time Spent: 191.52s, Test Accuracy: 12.00%\n",
      "Epoch: 10, Time Spent: 211.41s, Train Accuracy: 22.21%\n",
      "Epoch: 10, Time Spent: 213.11s, Test Accuracy: 21.70%\n",
      "Epoch: 11, Time Spent: 235.23s, Train Accuracy: 20.90%\n",
      "Epoch: 11, Time Spent: 235.75s, Test Accuracy: 21.30%\n",
      "Epoch: 12, Time Spent: 250.16s, Train Accuracy: 20.00%\n",
      "Epoch: 12, Time Spent: 250.42s, Test Accuracy: 20.30%\n",
      "Epoch: 13, Time Spent: 264.22s, Train Accuracy: 19.54%\n",
      "Epoch: 13, Time Spent: 264.46s, Test Accuracy: 19.60%\n",
      "Epoch: 14, Time Spent: 278.66s, Train Accuracy: 19.40%\n",
      "Epoch: 14, Time Spent: 278.89s, Test Accuracy: 19.40%\n",
      "Epoch: 15, Time Spent: 292.50s, Train Accuracy: 19.39%\n",
      "Epoch: 15, Time Spent: 292.76s, Test Accuracy: 19.20%\n",
      "Epoch: 16, Time Spent: 307.37s, Train Accuracy: 19.44%\n",
      "Epoch: 16, Time Spent: 307.65s, Test Accuracy: 19.20%\n",
      "Epoch: 17, Time Spent: 328.35s, Train Accuracy: 19.50%\n",
      "Epoch: 17, Time Spent: 328.61s, Test Accuracy: 19.30%\n",
      "Epoch: 18, Time Spent: 345.26s, Train Accuracy: 19.53%\n",
      "Epoch: 18, Time Spent: 345.52s, Test Accuracy: 19.40%\n",
      "Epoch: 19, Time Spent: 360.84s, Train Accuracy: 19.50%\n",
      "Epoch: 19, Time Spent: 361.17s, Test Accuracy: 19.30%\n",
      "Epoch: 20, Time Spent: 377.08s, Train Accuracy: 19.49%\n",
      "Epoch: 20, Time Spent: 377.36s, Test Accuracy: 19.10%\n"
     ]
    }
   ],
   "source": [
    "# 5 layer\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# def the function for convert label and image 28x28 into 1 + 728 and save as csv file\n",
    "def convert(imgf, labelf, outf, n):\n",
    "    f = open(imgf, \"rb\")\n",
    "    o = open(outf, \"w\")\n",
    "    l = open(labelf, \"rb\")\n",
    "\n",
    "    f.read(16)\n",
    "    l.read(8)\n",
    "    images = []\n",
    "\n",
    "    for i in range(n):\n",
    "        image = [ord(l.read(1))]\n",
    "        for j in range(28*28):\n",
    "            image.append(ord(f.read(1)))\n",
    "        images.append(image)\n",
    "\n",
    "    for image in images:\n",
    "        o.write(\",\".join(str(pix) for pix in image)+\"\\n\")\n",
    "    f.close()\n",
    "    o.close()\n",
    "    l.close()\n",
    "\n",
    "# convert mnist files in to csv\n",
    "#convert(\"train-images-idx3-ubyte\", \"train-labels-idx1-ubyte\", \"train_10000.csv\", 10000)\n",
    "#convert(\"t10k-images-idx3-ubyte\", \"t10k-labels-idx1-ubyte\", \"test_1000.csv\", 1000)\n",
    "\n",
    "train_file = open(\"train_10000.csv\", 'r')\n",
    "train_list = train_file.readlines()\n",
    "train_file.close()\n",
    "#len(train_list)\n",
    "test_file = open(\"test_1000.csv\", 'r')\n",
    "test_list = test_file.readlines()\n",
    "test_file.close()\n",
    "\n",
    "# NN building\n",
    "class DNN:\n",
    "  def __init__(self, sizes, epochs, lr):\n",
    "    self.sizes = sizes\n",
    "    self.epochs = epochs\n",
    "    self.lr = lr\n",
    "\n",
    "    # number of nodes in each layer\n",
    "    input_layer = self.sizes[0]\n",
    "    hidden_1 = self.sizes[1]\n",
    "    hidden_2 = self.sizes[2]\n",
    "    hidden_3 = self.sizes[3]\n",
    "    output_layer = self.sizes[4]\n",
    "\n",
    "    self.params = {\n",
    "        'W1': np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
    "        'W2': np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
    "        'W3': np.random.randn(hidden_3, hidden_2) * np.sqrt(1./ hidden_3),\n",
    "        'W4': np.random.randn(output_layer, hidden_3) * np.sqrt(1. / output_layer)\n",
    "    }\n",
    "  def sigmoid(self, x, derivative=False):\n",
    "      if derivative:\n",
    "          return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "      return 1/(1 + np.exp(-x))\n",
    "\n",
    "  def softmax(self, x, derivative=False):\n",
    "      # Numerically stable with large exponentials\n",
    "      exps = np.exp(x - x.max())\n",
    "      if derivative:\n",
    "          return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "      return exps / np.sum(exps, axis=0)\n",
    "  def forward_pass(self, x_train):\n",
    "      params = self.params\n",
    "\n",
    "      # input layer activations becomes sample\n",
    "      params['A0'] = x_train\n",
    "\n",
    "      # input layer to hidden layer 1\n",
    "      params['Z1'] = np.dot(params[\"W1\"], params['A0'])\n",
    "      params['A1'] = self.sigmoid(params['Z1'])\n",
    "\n",
    "      # hidden layer 1 to hidden layer 2\n",
    "      params['Z2'] = np.dot(params[\"W2\"], params['A1'])\n",
    "      params['A2'] = self.sigmoid(params['Z2'])\n",
    "\n",
    "      # hidden layer 2 to hidden layer 3\n",
    "      params['Z3'] = np.dot(params[\"W3\"], params['A2'])\n",
    "      params['A3'] = self.sigmoid(params['Z3'])\n",
    "\n",
    "      # hidden layer 3 to output layer\n",
    "      params['Z4'] = np.dot(params[\"W4\"], params['A3'])\n",
    "      params['A4'] = self.softmax(params['Z4'])\n",
    "\n",
    "      return params['A4']\n",
    "\n",
    "  def backward_pass(self, y_train, output):\n",
    "      params = self.params\n",
    "      change_w = {}\n",
    "\n",
    "      # Calculate W4 update\n",
    "      error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['Z4'], derivative=True)\n",
    "      change_w['W4'] = np.outer(error, params['A3'])\n",
    "\n",
    "      # Calculate W3 update\n",
    "      error = np.dot(params['W4'].T, error) * self.sigmoid(params['Z3'], derivative=True)\n",
    "      change_w['W3'] = np.outer(error, params['A2'])\n",
    "\n",
    "      # Calculate W2 update\n",
    "      error = np.dot(params['W3'].T, error) * self.sigmoid(params['Z2'], derivative=True)\n",
    "      change_w['W2'] = np.outer(error, params['A1'])\n",
    "\n",
    "      # Calculate W1 update\n",
    "      error = np.dot(params['W2'].T, error) * self.sigmoid(params['Z1'], derivative=True)\n",
    "      change_w['W1'] = np.outer(error, params['A0'])\n",
    "\n",
    "      return change_w\n",
    "\n",
    "  def update_network_parameters(self, changes_to_w):\n",
    "      for key, value in changes_to_w.items():\n",
    "          self.params[key] -= self.lr * value\n",
    "\n",
    "  def compute_accuracy(self, test_data, output_nodes):\n",
    "      predictions = []\n",
    "      for x in test_data:\n",
    "          all_values = x.split(',')\n",
    "          # scale and shift the inputs\n",
    "          inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "          # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "          targets = np.zeros(output_nodes) + 0.01\n",
    "          # all_values[0] is the target label for this record\n",
    "          targets[int(all_values[0])] = 0.99\n",
    "          output = self.forward_pass(inputs)\n",
    "          pred = np.argmax(output)\n",
    "          predictions.append(pred == np.argmax(targets))\n",
    "\n",
    "      return np.mean(predictions)\n",
    "\n",
    "  def train(self, train_list, test_list, output_nodes):\n",
    "      start_time = time.time()\n",
    "      for iteration in range(self.epochs):\n",
    "          for x in train_list:\n",
    "              all_values = x.split(',')\n",
    "              # scale and shift the inputs\n",
    "              inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "              # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "              targets = np.zeros(output_nodes) + 0.01\n",
    "              # all_values[0] is the target label for this record\n",
    "              targets[int(all_values[0])] = 0.99\n",
    "              output = self.forward_pass(inputs)\n",
    "              changes_to_w = self.backward_pass(targets, output)\n",
    "              self.update_network_parameters(changes_to_w)\n",
    "\n",
    "          accuracy_train = self.compute_accuracy(train_list, output_nodes)\n",
    "          print('Epoch: {0}, Time Spent: {1:.2f}s, Train Accuracy: {2:.2f}%'.format(\n",
    "              iteration+1, time.time() - start_time, accuracy_train * 100))\n",
    "\n",
    "          accuracy_test = self.compute_accuracy(test_list, output_nodes)\n",
    "          print('Epoch: {0}, Time Spent: {1:.2f}s, Test Accuracy: {2:.2f}%'.format(\n",
    "              iteration+1, time.time() - start_time, accuracy_test * 100))\n",
    "\n",
    "\n",
    "# run the NN\n",
    "dnn = DNN(sizes=[784, 256, 128, 64, 10], epochs=20, lr=0.001)\n",
    "dnn.train(train_list, test_list, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time Spent: 2.69s, Train Accuracy: 20.98%\n",
      "Epoch: 1, Time Spent: 3.36s, Test Accuracy: 10.12%\n",
      "Epoch: 2, Time Spent: 6.79s, Train Accuracy: 23.98%\n",
      "Epoch: 2, Time Spent: 8.24s, Test Accuracy: 10.32%\n",
      "Epoch: 3, Time Spent: 11.43s, Train Accuracy: 23.62%\n",
      "Epoch: 3, Time Spent: 12.16s, Test Accuracy: 10.26%\n",
      "Epoch: 4, Time Spent: 14.94s, Train Accuracy: 23.56%\n",
      "Epoch: 4, Time Spent: 15.75s, Test Accuracy: 10.19%\n",
      "Epoch: 5, Time Spent: 18.21s, Train Accuracy: 23.61%\n",
      "Epoch: 5, Time Spent: 18.90s, Test Accuracy: 10.39%\n",
      "Epoch: 6, Time Spent: 21.47s, Train Accuracy: 25.41%\n",
      "Epoch: 6, Time Spent: 22.23s, Test Accuracy: 10.15%\n",
      "Epoch: 7, Time Spent: 24.67s, Train Accuracy: 28.52%\n",
      "Epoch: 7, Time Spent: 25.46s, Test Accuracy: 10.48%\n",
      "Epoch: 8, Time Spent: 28.03s, Train Accuracy: 31.47%\n",
      "Epoch: 8, Time Spent: 28.63s, Test Accuracy: 10.54%\n",
      "Epoch: 9, Time Spent: 30.82s, Train Accuracy: 34.08%\n",
      "Epoch: 9, Time Spent: 31.45s, Test Accuracy: 10.27%\n",
      "Epoch: 10, Time Spent: 34.17s, Train Accuracy: 34.97%\n",
      "Epoch: 10, Time Spent: 34.79s, Test Accuracy: 10.29%\n",
      "Epoch: 11, Time Spent: 37.29s, Train Accuracy: 35.38%\n",
      "Epoch: 11, Time Spent: 38.09s, Test Accuracy: 10.22%\n",
      "Epoch: 12, Time Spent: 40.89s, Train Accuracy: 35.69%\n",
      "Epoch: 12, Time Spent: 41.55s, Test Accuracy: 10.29%\n",
      "Epoch: 13, Time Spent: 44.22s, Train Accuracy: 35.99%\n",
      "Epoch: 13, Time Spent: 44.84s, Test Accuracy: 10.39%\n",
      "Epoch: 14, Time Spent: 47.57s, Train Accuracy: 36.31%\n",
      "Epoch: 14, Time Spent: 48.21s, Test Accuracy: 10.45%\n",
      "Epoch: 15, Time Spent: 50.84s, Train Accuracy: 36.71%\n",
      "Epoch: 15, Time Spent: 51.56s, Test Accuracy: 10.32%\n",
      "Epoch: 16, Time Spent: 54.04s, Train Accuracy: 37.25%\n",
      "Epoch: 16, Time Spent: 54.82s, Test Accuracy: 10.44%\n",
      "Epoch: 17, Time Spent: 57.44s, Train Accuracy: 37.77%\n",
      "Epoch: 17, Time Spent: 58.24s, Test Accuracy: 10.41%\n",
      "Epoch: 18, Time Spent: 61.05s, Train Accuracy: 38.29%\n",
      "Epoch: 18, Time Spent: 61.69s, Test Accuracy: 10.48%\n",
      "Epoch: 19, Time Spent: 64.04s, Train Accuracy: 38.78%\n",
      "Epoch: 19, Time Spent: 64.65s, Test Accuracy: 10.43%\n",
      "Epoch: 20, Time Spent: 67.43s, Train Accuracy: 39.41%\n",
      "Epoch: 20, Time Spent: 68.08s, Test Accuracy: 10.46%\n"
     ]
    }
   ],
   "source": [
    "# 4 layer with PCA\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.datasets import mnist\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "TRAIN_NUM = 10000\n",
    "TEST_NUM = 100\n",
    "COMPONENT_NUM = 30\n",
    "\n",
    "def import_data(TRAIN_NUM, TEST_NUM):\n",
    "    TRAIN_DATA_3D = np.empty((TRAIN_NUM, 28, 28))\n",
    "    TRAIN_LABEL = np.empty(TRAIN_NUM)\n",
    "    TEST_DATA_3D = np.empty((TEST_NUM, 28, 28))\n",
    "    TEST_LABEL = np.empty(TEST_NUM)\n",
    "    TRAIN_DATA_3D[0: TRAIN_NUM] = X_TRAIN[0: TRAIN_NUM]\n",
    "    TRAIN_LABEL[0: TRAIN_NUM] = Y_TRAIN[0: TRAIN_NUM]\n",
    "    TEST_DATA_3D[0: TEST_NUM] = X_TEST[0: TEST_NUM]\n",
    "    TEST_LABEL[0: TEST_NUM] = Y_TEST[0: TEST_NUM]\n",
    "    TRAIN_DATA_2D = TRAIN_DATA_3D.reshape(TRAIN_NUM, -1)\n",
    "    TEST_DATA_2D = TEST_DATA_3D.reshape(TEST_NUM, -1)\n",
    "    return TRAIN_DATA_2D, TRAIN_LABEL, TEST_DATA_2D, TEST_LABEL\n",
    "\n",
    "def pca_dimension_reduce(TRAIN_DATA, TEST_DATA, COMPONENT_NUM):\n",
    "    pca = PCA(n_components = COMPONENT_NUM)\n",
    "    train_reduce = pca.fit_transform(TRAIN_DATA)\n",
    "    test_reduce = pca.transform(TEST_DATA)\n",
    "    return train_reduce, test_reduce\n",
    "\n",
    "def data_transform(PCA_reduce_list, labelf):\n",
    "    output = np.zeros((len(PCA_reduce_list), 31))\n",
    "    for i in range(len(PCA_reduce_list)):\n",
    "        output[i, 0] = labelf[i]\n",
    "        output[i, 1:31] = PCA_reduce_list[i]\n",
    "        farray = output.astype(float)\n",
    "    return farray\n",
    "\n",
    "(X_TRAIN, Y_TRAIN), (X_TEST, Y_TEST) = mnist.load_data()\n",
    "TRAIN_DATA, TRAIN_LABEL, TEST_DATA, TEST_LABEL = import_data(TRAIN_NUM, TEST_NUM)\n",
    "TRAIN_REDUCE, TEST_REDUCE = pca_dimension_reduce(TRAIN_DATA, TEST_DATA, COMPONENT_NUM)\n",
    "train_list = data_transform(TRAIN_REDUCE, Y_TRAIN)\n",
    "test_list = data_transform(TRAIN_REDUCE, Y_TEST)\n",
    "np.savetxt('train.pca30.csv', train_list, delimiter = ',', fmt='%.0f')\n",
    "np.savetxt('test.pca30.csv', test_list, delimiter = ',', fmt='%.0f')\n",
    "\n",
    "train_file = open(\"train.pca30.csv\", 'r')\n",
    "train_list = train_file.readlines()\n",
    "train_file.close()\n",
    "#len(train_list)\n",
    "test_file = open(\"test.pca30.csv\", 'r')\n",
    "test_list = test_file.readlines()\n",
    "test_file.close()\n",
    "\n",
    "# NN building\n",
    "class DNN:\n",
    "  def __init__(self, sizes, epochs, lr):\n",
    "    self.sizes = sizes\n",
    "    self.epochs = epochs\n",
    "    self.lr = lr\n",
    "\n",
    "    # number of nodes in each layer\n",
    "    input_layer=self.sizes[0]\n",
    "    hidden_1=self.sizes[1]\n",
    "    hidden_2=self.sizes[2]\n",
    "    output_layer=self.sizes[3]\n",
    "\n",
    "    self.params = {\n",
    "        'W1':np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
    "        'W2':np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
    "        'W3':np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
    "    }\n",
    "  def sigmoid(self, x, derivative=False):\n",
    "      if derivative:\n",
    "          return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "      return 1/(1 + np.exp(-x))\n",
    "\n",
    "  def softmax(self, x, derivative=False):\n",
    "      # Numerically stable with large exponentials\n",
    "      exps = np.exp(x - x.max())\n",
    "      if derivative:\n",
    "          return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "      return exps / np.sum(exps, axis=0)\n",
    "  def forward_pass(self, x_train):\n",
    "      params = self.params\n",
    "\n",
    "      # input layer activations becomes sample\n",
    "      params['A0'] = x_train\n",
    "\n",
    "      # input layer to hidden layer 1\n",
    "      params['Z1'] = np.dot(params[\"W1\"], params['A0'])\n",
    "      params['A1'] = self.sigmoid(params['Z1'])\n",
    "\n",
    "      # hidden layer 1 to hidden layer 2\n",
    "      params['Z2'] = np.dot(params[\"W2\"], params['A1'])\n",
    "      params['A2'] = self.sigmoid(params['Z2'])\n",
    "\n",
    "      # hidden layer 2 to output layer\n",
    "      params['Z3'] = np.dot(params[\"W3\"], params['A2'])\n",
    "      params['A3'] = self.softmax(params['Z3'])\n",
    "\n",
    "      return params['A3']\n",
    "\n",
    "  def backward_pass(self, y_train, output):\n",
    "      params = self.params\n",
    "      change_w = {}\n",
    "\n",
    "      # Calculate W3 update\n",
    "      error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['Z3'], derivative=True)\n",
    "      change_w['W3'] = np.outer(error, params['A2'])\n",
    "\n",
    "      # Calculate W2 update\n",
    "      error = np.dot(params['W3'].T, error) * self.sigmoid(params['Z2'], derivative=True)\n",
    "      change_w['W2'] = np.outer(error, params['A1'])\n",
    "\n",
    "      # Calculate W1 update\n",
    "      error = np.dot(params['W2'].T, error) * self.sigmoid(params['Z1'], derivative=True)\n",
    "      change_w['W1'] = np.outer(error, params['A0'])\n",
    "\n",
    "      return change_w\n",
    "\n",
    "  def update_network_parameters(self, changes_to_w):\n",
    "      for key, value in changes_to_w.items():\n",
    "          self.params[key] -= self.lr * value\n",
    "\n",
    "  def compute_accuracy(self, test_data, output_nodes):\n",
    "      predictions = []\n",
    "      for x in test_data:\n",
    "          all_values = x.split(',')\n",
    "          # scale and shift the inputs\n",
    "          inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "          # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "          targets = np.zeros(output_nodes) + 0.01\n",
    "          # all_values[0] is the target label for this record\n",
    "          targets[int(all_values[0])] = 0.99\n",
    "          output = self.forward_pass(inputs)\n",
    "          pred = np.argmax(output)\n",
    "          predictions.append(pred == np.argmax(targets))\n",
    "\n",
    "      return np.mean(predictions)\n",
    "\n",
    "  def train(self, train_list, test_list, output_nodes):\n",
    "      start_time = time.time()\n",
    "      for iteration in range(self.epochs):\n",
    "          for x in train_list:\n",
    "              all_values = x.split(',')\n",
    "              # scale and shift the inputs\n",
    "              inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "              # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "              targets = np.zeros(output_nodes) + 0.01\n",
    "              # all_values[0] is the target label for this record\n",
    "              targets[int(all_values[0])] = 0.99\n",
    "              output = self.forward_pass(inputs)\n",
    "              changes_to_w = self.backward_pass(targets, output)\n",
    "              self.update_network_parameters(changes_to_w)\n",
    "\n",
    "          accuracy_train = self.compute_accuracy(train_list, output_nodes)\n",
    "          print('Epoch: {0}, Time Spent: {1:.2f}s, Train Accuracy: {2:.2f}%'.format(\n",
    "              iteration+1, time.time() - start_time, accuracy_train * 100))\n",
    "\n",
    "          accuracy_test = self.compute_accuracy(test_list, output_nodes)\n",
    "          print('Epoch: {0}, Time Spent: {1:.2f}s, Test Accuracy: {2:.2f}%'.format(\n",
    "              iteration+1, time.time() - start_time, accuracy_test * 100))\n",
    "\n",
    "\n",
    "# run the NN\n",
    "dnn = DNN(sizes=[30, 128, 64, 10], epochs=20, lr=0.001)\n",
    "dnn.train(train_list, test_list, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time Spent: 5.29s, Train Accuracy: 19.40%\n",
      "Epoch: 1, Time Spent: 6.26s, Test Accuracy: 10.65%\n",
      "Epoch: 2, Time Spent: 12.61s, Train Accuracy: 18.85%\n",
      "Epoch: 2, Time Spent: 17.93s, Test Accuracy: 10.86%\n",
      "Epoch: 3, Time Spent: 23.03s, Train Accuracy: 18.70%\n",
      "Epoch: 3, Time Spent: 24.23s, Test Accuracy: 10.94%\n",
      "Epoch: 4, Time Spent: 29.35s, Train Accuracy: 18.65%\n",
      "Epoch: 4, Time Spent: 30.70s, Test Accuracy: 10.98%\n",
      "Epoch: 5, Time Spent: 35.05s, Train Accuracy: 18.57%\n",
      "Epoch: 5, Time Spent: 36.19s, Test Accuracy: 11.04%\n",
      "Epoch: 6, Time Spent: 41.00s, Train Accuracy: 18.61%\n",
      "Epoch: 6, Time Spent: 41.91s, Test Accuracy: 11.07%\n",
      "Epoch: 7, Time Spent: 47.32s, Train Accuracy: 18.67%\n",
      "Epoch: 7, Time Spent: 48.33s, Test Accuracy: 11.09%\n",
      "Epoch: 8, Time Spent: 53.15s, Train Accuracy: 18.84%\n",
      "Epoch: 8, Time Spent: 54.08s, Test Accuracy: 11.10%\n",
      "Epoch: 9, Time Spent: 58.91s, Train Accuracy: 19.20%\n",
      "Epoch: 9, Time Spent: 60.14s, Test Accuracy: 11.07%\n",
      "Epoch: 10, Time Spent: 65.59s, Train Accuracy: 19.49%\n",
      "Epoch: 10, Time Spent: 66.80s, Test Accuracy: 11.09%\n",
      "Epoch: 11, Time Spent: 72.20s, Train Accuracy: 19.84%\n",
      "Epoch: 11, Time Spent: 73.17s, Test Accuracy: 10.97%\n",
      "Epoch: 12, Time Spent: 78.52s, Train Accuracy: 20.25%\n",
      "Epoch: 12, Time Spent: 79.56s, Test Accuracy: 10.95%\n",
      "Epoch: 13, Time Spent: 84.92s, Train Accuracy: 20.65%\n",
      "Epoch: 13, Time Spent: 85.91s, Test Accuracy: 11.00%\n",
      "Epoch: 14, Time Spent: 91.08s, Train Accuracy: 21.24%\n",
      "Epoch: 14, Time Spent: 92.03s, Test Accuracy: 11.02%\n",
      "Epoch: 15, Time Spent: 97.05s, Train Accuracy: 21.69%\n",
      "Epoch: 15, Time Spent: 98.24s, Test Accuracy: 10.94%\n",
      "Epoch: 16, Time Spent: 103.37s, Train Accuracy: 22.13%\n",
      "Epoch: 16, Time Spent: 104.38s, Test Accuracy: 10.96%\n",
      "Epoch: 17, Time Spent: 109.57s, Train Accuracy: 22.48%\n",
      "Epoch: 17, Time Spent: 110.56s, Test Accuracy: 11.04%\n",
      "Epoch: 18, Time Spent: 115.52s, Train Accuracy: 22.92%\n",
      "Epoch: 18, Time Spent: 116.43s, Test Accuracy: 11.00%\n",
      "Epoch: 19, Time Spent: 121.47s, Train Accuracy: 23.20%\n",
      "Epoch: 19, Time Spent: 122.79s, Test Accuracy: 11.06%\n",
      "Epoch: 20, Time Spent: 128.79s, Train Accuracy: 23.57%\n",
      "Epoch: 20, Time Spent: 129.82s, Test Accuracy: 10.98%\n"
     ]
    }
   ],
   "source": [
    "# 5 layer with PCA\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.datasets import mnist\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "TRAIN_NUM = 10000\n",
    "TEST_NUM = 100\n",
    "COMPONENT_NUM = 30\n",
    "\n",
    "def import_data(TRAIN_NUM, TEST_NUM):\n",
    "    TRAIN_DATA_3D = np.empty((TRAIN_NUM, 28, 28))\n",
    "    TRAIN_LABEL = np.empty(TRAIN_NUM)\n",
    "    TEST_DATA_3D = np.empty((TEST_NUM, 28, 28))\n",
    "    TEST_LABEL = np.empty(TEST_NUM)\n",
    "    TRAIN_DATA_3D[0: TRAIN_NUM] = X_TRAIN[0: TRAIN_NUM]\n",
    "    TRAIN_LABEL[0: TRAIN_NUM] = Y_TRAIN[0: TRAIN_NUM]\n",
    "    TEST_DATA_3D[0: TEST_NUM] = X_TEST[0: TEST_NUM]\n",
    "    TEST_LABEL[0: TEST_NUM] = Y_TEST[0: TEST_NUM]\n",
    "    TRAIN_DATA_2D = TRAIN_DATA_3D.reshape(TRAIN_NUM, -1)\n",
    "    TEST_DATA_2D = TEST_DATA_3D.reshape(TEST_NUM, -1)\n",
    "    return TRAIN_DATA_2D, TRAIN_LABEL, TEST_DATA_2D, TEST_LABEL\n",
    "\n",
    "def pca_dimension_reduce(TRAIN_DATA, TEST_DATA, COMPONENT_NUM):\n",
    "    pca = PCA(n_components = COMPONENT_NUM)\n",
    "    train_reduce = pca.fit_transform(TRAIN_DATA)\n",
    "    test_reduce = pca.transform(TEST_DATA)\n",
    "    return train_reduce, test_reduce\n",
    "\n",
    "def data_transform(PCA_reduce_list, labelf):\n",
    "    output = np.zeros((len(PCA_reduce_list), 31))\n",
    "    for i in range(len(PCA_reduce_list)):\n",
    "        output[i, 0] = labelf[i]\n",
    "        output[i, 1:31] = PCA_reduce_list[i]\n",
    "        farray = output.astype(float)\n",
    "    return farray\n",
    "\n",
    "(X_TRAIN, Y_TRAIN), (X_TEST, Y_TEST) = mnist.load_data()\n",
    "TRAIN_DATA, TRAIN_LABEL, TEST_DATA, TEST_LABEL = import_data(TRAIN_NUM, TEST_NUM)\n",
    "TRAIN_REDUCE, TEST_REDUCE = pca_dimension_reduce(TRAIN_DATA, TEST_DATA, COMPONENT_NUM)\n",
    "train_list = data_transform(TRAIN_REDUCE, Y_TRAIN)\n",
    "test_list = data_transform(TRAIN_REDUCE, Y_TEST)\n",
    "np.savetxt('train.pca30.csv', train_list, delimiter = ',', fmt='%.0f')\n",
    "np.savetxt('test.pca30.csv', test_list, delimiter = ',', fmt='%.0f')\n",
    "\n",
    "train_file = open(\"train.pca30.csv\", 'r')\n",
    "train_list = train_file.readlines()\n",
    "train_file.close()\n",
    "#len(train_list)\n",
    "test_file = open(\"test.pca30.csv\", 'r')\n",
    "test_list = test_file.readlines()\n",
    "test_file.close()\n",
    "\n",
    "# NN building\n",
    "class DNN:\n",
    "  def __init__(self, sizes, epochs, lr):\n",
    "    self.sizes = sizes\n",
    "    self.epochs = epochs\n",
    "    self.lr = lr\n",
    "\n",
    "    # number of nodes in each layer\n",
    "    input_layer = self.sizes[0]\n",
    "    hidden_1 = self.sizes[1]\n",
    "    hidden_2 = self.sizes[2]\n",
    "    hidden_3 = self.sizes[3]\n",
    "    output_layer = self.sizes[4]\n",
    "\n",
    "    self.params = {\n",
    "        'W1': np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
    "        'W2': np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
    "        'W3': np.random.randn(hidden_3, hidden_2) * np.sqrt(1./ hidden_3),\n",
    "        'W4': np.random.randn(output_layer, hidden_3) * np.sqrt(1. / output_layer)\n",
    "    }\n",
    "  def sigmoid(self, x, derivative=False):\n",
    "      if derivative:\n",
    "          return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "      return 1/(1 + np.exp(-x))\n",
    "\n",
    "  def softmax(self, x, derivative=False):\n",
    "      # Numerically stable with large exponentials\n",
    "      exps = np.exp(x - x.max())\n",
    "      if derivative:\n",
    "          return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "      return exps / np.sum(exps, axis=0)\n",
    "  def forward_pass(self, x_train):\n",
    "      params = self.params\n",
    "\n",
    "      # input layer activations becomes sample\n",
    "      params['A0'] = x_train\n",
    "\n",
    "      # input layer to hidden layer 1\n",
    "      params['Z1'] = np.dot(params[\"W1\"], params['A0'])\n",
    "      params['A1'] = self.sigmoid(params['Z1'])\n",
    "\n",
    "      # hidden layer 1 to hidden layer 2\n",
    "      params['Z2'] = np.dot(params[\"W2\"], params['A1'])\n",
    "      params['A2'] = self.sigmoid(params['Z2'])\n",
    "\n",
    "      # hidden layer 2 to hidden layer 3\n",
    "      params['Z3'] = np.dot(params[\"W3\"], params['A2'])\n",
    "      params['A3'] = self.sigmoid(params['Z3'])\n",
    "\n",
    "      # hidden layer 3 to output layer\n",
    "      params['Z4'] = np.dot(params[\"W4\"], params['A3'])\n",
    "      params['A4'] = self.softmax(params['Z4'])\n",
    "\n",
    "      return params['A4']\n",
    "\n",
    "  def backward_pass(self, y_train, output):\n",
    "      params = self.params\n",
    "      change_w = {}\n",
    "\n",
    "      # Calculate W4 update\n",
    "      error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['Z4'], derivative=True)\n",
    "      change_w['W4'] = np.outer(error, params['A3'])\n",
    "\n",
    "      # Calculate W3 update\n",
    "      error = np.dot(params['W4'].T, error) * self.sigmoid(params['Z3'], derivative=True)\n",
    "      change_w['W3'] = np.outer(error, params['A2'])\n",
    "\n",
    "      # Calculate W2 update\n",
    "      error = np.dot(params['W3'].T, error) * self.sigmoid(params['Z2'], derivative=True)\n",
    "      change_w['W2'] = np.outer(error, params['A1'])\n",
    "\n",
    "      # Calculate W1 update\n",
    "      error = np.dot(params['W2'].T, error) * self.sigmoid(params['Z1'], derivative=True)\n",
    "      change_w['W1'] = np.outer(error, params['A0'])\n",
    "\n",
    "      return change_w\n",
    "\n",
    "  def update_network_parameters(self, changes_to_w):\n",
    "      for key, value in changes_to_w.items():\n",
    "          self.params[key] -= self.lr * value\n",
    "\n",
    "  def compute_accuracy(self, test_data, output_nodes):\n",
    "      predictions = []\n",
    "      for x in test_data:\n",
    "          all_values = x.split(',')\n",
    "          # scale and shift the inputs\n",
    "          inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "          # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "          targets = np.zeros(output_nodes) + 0.01\n",
    "          # all_values[0] is the target label for this record\n",
    "          targets[int(all_values[0])] = 0.99\n",
    "          output = self.forward_pass(inputs)\n",
    "          pred = np.argmax(output)\n",
    "          predictions.append(pred == np.argmax(targets))\n",
    "\n",
    "      return np.mean(predictions)\n",
    "\n",
    "  def train(self, train_list, test_list, output_nodes):\n",
    "      start_time = time.time()\n",
    "      for iteration in range(self.epochs):\n",
    "          for x in train_list:\n",
    "              all_values = x.split(',')\n",
    "              # scale and shift the inputs\n",
    "              inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "              # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "              targets = np.zeros(output_nodes) + 0.01\n",
    "              # all_values[0] is the target label for this record\n",
    "              targets[int(all_values[0])] = 0.99\n",
    "              output = self.forward_pass(inputs)\n",
    "              changes_to_w = self.backward_pass(targets, output)\n",
    "              self.update_network_parameters(changes_to_w)\n",
    "\n",
    "          accuracy_train = self.compute_accuracy(train_list, output_nodes)\n",
    "          print('Epoch: {0}, Time Spent: {1:.2f}s, Train Accuracy: {2:.2f}%'.format(\n",
    "              iteration+1, time.time() - start_time, accuracy_train * 100))\n",
    "\n",
    "          accuracy_test = self.compute_accuracy(test_list, output_nodes)\n",
    "          print('Epoch: {0}, Time Spent: {1:.2f}s, Test Accuracy: {2:.2f}%'.format(\n",
    "              iteration+1, time.time() - start_time, accuracy_test * 100))\n",
    "\n",
    "\n",
    "# run the NN\n",
    "dnn = DNN(sizes=[30, 256, 128, 64, 10], epochs=20, lr=0.001)\n",
    "dnn.train(train_list, test_list, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}